{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b91c9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8470ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents.middleware import SummarizationMiddleware \n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41da2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42af3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchReport(BaseModel):\n",
    "    title: str = Field(description=\"Catchy title\")\n",
    "    summary: str = Field(description=\"2-sentence summary\")\n",
    "    sources: List[str] = Field(description=\"List of URLs\")\n",
    "    confidence_score: float = Field(description=\"0 to 1\")\n",
    "\n",
    "class ValidationResult(BaseModel):\n",
    "    is_valid: bool = Field(description=\"True if facts are dated for 2026\")\n",
    "    critique: str = Field(description=\"Explanation of gaps\")\n",
    "    # Using a literal ensures the LLM picks ONLY one of these two strings\n",
    "    needed_action: Literal[\"finalize\", \"research_more\"] = Field(\n",
    "        description=\"Must be 'finalize' or 'research_more'\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c8f7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "llm = ChatGroq(model=\"qwen/qwen3-32b\", temperature=0) # Use 0 temp for extraction\n",
    "tools = [TavilySearchResults(max_results=3)]\n",
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3492075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validaiton_PROMPT = \"\"\"You are an expert Research Agent. \n",
    "Step 1: Use your tools to find information.\n",
    "Step 2: Self-Reflect. Look at your findings. If they are vague or missing dates, search again.\n",
    "Step 3: Only provide the final answer once you are confident the data is accurate for 2026.\"\"\"\n",
    "\n",
    "Resarch_PROMPT = \"\"\"You are a professional researcher. Search the web and then provide a structured report.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d646e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumMiddleware=SummarizationMiddleware(\n",
    "#     model=llm,\n",
    "#     trigger=(\"messages\",2),\n",
    "#     keep=(\"messages\",10)\n",
    "# )\n",
    "\n",
    "\n",
    "sum_middleware = SummarizationMiddleware(\n",
    "    model=llm,\n",
    "    trigger=(\"tokens\", 500), # Summarize after 5 messages\n",
    "    keep=(\"tokens\", 10000)      # Keep the most recent 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2f3f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "research_parser = llm.with_structured_output(ResearchReport)\n",
    "validation_parser = llm.with_structured_output(ValidationResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d5c74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "research_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    checkpointer=memory,\n",
    "    middleware=[sum_middleware],\n",
    "    system_prompt=\"You are a 2026 research specialist. Search and find hard facts.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b36c1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validated_research(query: str):\n",
    "    config = {\"configurable\": {\"thread_id\": \"starship_2026\"}}\n",
    "    \n",
    "    # Step 1: Research\n",
    "    print(\"Researching...\")\n",
    "    state = research_agent.invoke({\"messages\": [(\"user\", query)]}, config=config)\n",
    "    raw_draft = state[\"messages\"][-1].content\n",
    "    \n",
    "    # Step 2: Validate (Using the parser to enforce the schema)\n",
    "    print(\"Validating...\")\n",
    "    # Instruction to follow the schema strictly\n",
    "    v_prompt = f\"Critique this research for 2026 accuracy. Output must include needed_action.\\n\\n{raw_draft}\"\n",
    "    \n",
    "    try:\n",
    "        validation = validation_parser.invoke(v_prompt)\n",
    "    except Exception:\n",
    "        # Emergency fallback \n",
    "        validation = ValidationResult(is_valid=False, critique=\"Schema failed\", needed_action=\"research_more\")\n",
    "\n",
    "    if not validation.is_valid:\n",
    "        print(f\"Validation Failed: {validation.critique}\")\n",
    "        # Step 3: Revise\n",
    "        state = research_agent.invoke(\n",
    "            {\"messages\": [(\"user\", f\"Fix your report based on this: {validation.critique}\")]},\n",
    "            config=config\n",
    "        )\n",
    "        raw_draft = state[\"messages\"][-1].content\n",
    "\n",
    "    # Step 4: Final Structure\n",
    "    return research_parser.invoke(raw_draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f570c569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researching...\n",
      "Validating...\n",
      "Validation Failed: The research contains speculative claims about 2026 events (e.g., March 2026 launch, V3 details) that cannot be verified as of October 2023. Specifics like 'six weeks from January 26, 2026' and 'structural anomaly in late 2025' are future events with no current documentation. Sources like Wikipedia and the cited articles (from 2026) do not exist in the present timeline. The timeline assumes rapid Starship iteration (12th flight test by 2026) inconsistent with SpaceX’s historical delays.\n"
     ]
    }
   ],
   "source": [
    "report = run_validated_research(\"What are the latest updates on SpaceX Starship 2026?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0de20817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchReport(title='SpaceX Starship Development Update: Key Milestones and Future Plans (October 2023)', summary='As of October 2023, SpaceX has completed five Starship flight tests, with the latest achieving a successful high-altitude flight and booster landing. Upcoming plans focus on 2024 test flights and Raptor V3 engine integration by 2025, pending regulatory approvals.', sources=['https://en.wikipedia.org/wiki/Starship_(spacecraft)', 'https://www.faa.gov/', 'https://www.spacex.com/', 'https://www.nasa.gov/artemis'], confidence_score=0.9)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b70e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL STRUCTURED REPORT ---\n",
      "Title: SpaceX Starship Development Update: Key Milestones and Future Plans (October 2023)\n",
      "Summary: As of October 2023, SpaceX has completed five Starship flight tests, with the latest achieving a successful high-altitude flight and booster landing. Upcoming plans focus on 2024 test flights and Raptor V3 engine integration by 2025, pending regulatory approvals.\n",
      "Sources: ['https://en.wikipedia.org/wiki/Starship_(spacecraft)', 'https://www.faa.gov/', 'https://www.spacex.com/', 'https://www.nasa.gov/artemis']\n",
      "Confidence: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- FINAL STRUCTURED REPORT ---\")\n",
    "print(f\"Title: {report.title}\")\n",
    "print(f\"Summary: {report.summary}\")\n",
    "print(f\"Sources: {report.sources}\")\n",
    "print(f\"Confidence: {report.confidence_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f47848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sending messages to trigger summarization ---\n",
      "Total messages in history: 4\n",
      "Summarization successful! The message list was truncated.\n",
      "Earliest message now is: Here is a summary of the conversation to date:\n",
      "\n",
      "<t...\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test_session\"}}\n",
    "\n",
    "# 1. Force a long conversation to hit the trigger (e.g., 5 messages)\n",
    "print(\"--- Sending messages to trigger summarization ---\")\n",
    "for i in range(3):\n",
    "    research_agent.invoke({\"messages\": [(\"user\", f\"Tell me fact number {i} about Starship\")]}, config=config)\n",
    "\n",
    "# 2. Get the state properly\n",
    "state = research_agent.get_state(config)\n",
    "\n",
    "# 3. Access the messages\n",
    "messages = state.values.get(\"messages\", [])\n",
    "\n",
    "print(f\"Total messages in history: {len(messages)}\")\n",
    "\n",
    "# 4. Verification Logic\n",
    "if len(messages) < 6:\n",
    "    print(\"Summarization successful! The message list was truncated.\")\n",
    "    print(f\"Earliest message now is: {messages[0].content}...\")\n",
    "else:\n",
    "    print(\"Summarization not triggered. Check your middleware 'trigger' count.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1fb05d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Here is a summary of the conversation to date:\\n\\n<think>\\nOkay, let\\'s see. The user is asking for fact number 1 about Starship. From the conversation history, I need to extract the most relevant context.\\n\\nLooking back, the user previously asked for fact 0, and the assistant provided details about Starship\\'s structure and reusability. Now, the user is moving on to fact 1. In the history, there\\'s a mention of the Raptor engines and propulsion system as the next fact. The assistant had outlined that fact 1 would cover the Raptor engines, their design, and the use of methane-based fuel.\\n\\nI need to structure this into the required sections. The session intent is still the user\\'s goal to get a series of facts about Starship. The summary should include the key points about the Raptor engines, their specifications, and why methane is used. Artifacts are none since no files are mentioned. Next steps would be to present fact 1 and ask if the user wants to proceed to fact 2.\\n</think>\\n\\n## SESSION INTENT  \\nThe user is requesting a structured, numbered fact series about Starship, with a focus on technical specifications and mission objectives.  \\n\\n## SUMMARY  \\n- **Fact 1**: Starship is powered by **Raptor engines**, SpaceX\\'s most advanced **methane-fueled rocket engines**.  \\n  - **Design**: Each Raptor engine produces **~230 tons of thrust** in vacuum, using **liquid methane (CH₄)** and **liquid oxygen (LOX)** as propellants.  \\n  - **Advantages**: Methane is chosen for its **high specific impulse**, **clean combustion**, and potential for **in-situ resource utilization (ISRU)** on Mars.  \\n  - **Configuration**: The Starship spacecraft uses **6 Raptor engines** (3 for landing, 3 for ascent), while the Super Heavy booster uses **33 Raptor engines**.  \\n\\n## ARTIFACTS  \\nNone  \\n\\n## NEXT STEPS  \\n- Present \"Fact 1\" as defined above.  \\n- Ask if the user wants to continue with \"Fact 2\" (e.g., **thermal protection system** and **heat shield materials**).', additional_kwargs={'lc_source': 'summarization'}, response_metadata={}, id='56f81261-d869-492b-acc9-70953db97107'),\n",
       " AIMessage(content='## SESSION INTENT  \\nThe user is requesting a structured, numbered fact series about Starship, with a focus on technical specifications and mission objectives.  \\n\\n## SUMMARY  \\n- **Fact 1**: Starship is powered by **Raptor engines**, SpaceX\\'s most advanced propulsion system.  \\n  - **Design**: Uses **methane (CH₄) and liquid oxygen (LOX)** as propellants, enabling in-situ resource utilization (ISRU) on Mars.  \\n  - **Performance**: Each Raptor engine produces **~230 tons of thrust** (sea-level variant) or **~350 tons of thrust** (vacuum variant).  \\n  - **Full-flow staged combustion cycle**: Maximizes efficiency and reusability.  \\n  - **Redundancy**: Starship has **6 Raptor engines** (with 1 as a backup) for safe landing and mission flexibility.  \\n\\n## ARTIFACTS  \\nNone  \\n\\n## NEXT STEPS  \\n- Present \"Fact 1\" as defined above.  \\n- Ask if the user wants to continue with \"Fact 2\" (e.g., **thermal protection system** or **cargo/passenger capabilities**).', additional_kwargs={'reasoning_content': \"Okay, the user is asking for fact number 1 about Starship. Let me check the conversation history to see what facts have been covered so far.\\n\\nIn the previous messages, the user first asked for fact 0, which was about the structure and reusability of Starship. The assistant provided details on the stainless steel construction, reusability, and mission goals. Then the user asked for fact 1, and the assistant mentioned Raptor engines and propulsion. Now the user is asking again for fact 1, so maybe they want more details or a different aspect.\\n\\nWait, looking at the latest summary, the assistant listed fact 0 as the design and reusability, and the next step was to present fact 1 about Raptor engines. But the user is now asking for fact 1 again. Maybe there was a mix-up in the numbering. Let me confirm the facts covered so far.\\n\\nIn the first summary, fact 0 was about structure and reusability. Then in the second summary, fact 0 was about the super-heavy-lift launch vehicle, stages, capacity, and reusability. The user might be following the second summary's numbering. So fact 1 in the second summary was about Raptor engines and propulsion. The user is now asking for fact 1, so the assistant should provide that information.\\n\\nI need to make sure the answer aligns with the latest summary. The assistant should present fact 1 as the Raptor engines and propulsion system, including details like the number of engines, fuel type, thrust, and how they enable landing. Also, mention the use of methane and oxygen, and the full-flow staged combustion cycle. Then, proceed to ask if the user wants to continue to fact 2, which might be about the thermal protection system or another component.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 617, 'prompt_tokens': 987, 'total_tokens': 1604, 'completion_time': 1.216659994, 'completion_tokens_details': {'reasoning_tokens': 369}, 'prompt_time': 0.041131182, 'prompt_tokens_details': None, 'queue_time': 0.050763558, 'total_time': 1.257791176}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c14ad-d14a-7832-bd81-ae4bdc6169c7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 987, 'output_tokens': 617, 'total_tokens': 1604, 'output_token_details': {'reasoning': 369}}),\n",
       " HumanMessage(content='Tell me fact number 2 about Starship', additional_kwargs={}, response_metadata={}, id='c049688b-4cb7-449d-8f69-ba061e96e323'),\n",
       " AIMessage(content='## SESSION INTENT  \\nThe user is requesting a structured, numbered fact series about Starship, with a focus on technical specifications and mission objectives.  \\n\\n## SUMMARY  \\n- **Fact 2**: Starship’s **thermal protection system (TPS)** is designed to withstand extreme temperatures during re-entry into Earth or Mars atmospheres.  \\n  - **Heat Shield**: Uses **PICA-X** (Phenolic Impregnated Carbon Ablator), a lightweight, ablative material developed by SpaceX, capable of enduring temperatures up to **3,000°F (1,650°C)**.  \\n  - **Tile System**: Complements the heat shield with **ceramic tiles** on the spacecraft’s body, providing insulation and structural integrity.  \\n  - **Reusability**: The TPS is engineered for **rapid refurbishment** between missions, aligning with Starship’s goal of full reusability to reduce costs.  \\n  - **Testing**: Demonstrated in test flights (e.g., **SN8–SN15 prototypes**) and the **DM-2** orbital flight, with iterative improvements to address ablation and thermal stress.  \\n\\n## ARTIFACTS  \\nNone  \\n\\n## NEXT STEPS  \\n- Present \"Fact 2\" as defined above.  \\n- Ask if the user wants to continue with \"Fact 3\" (e.g., **cargo/passenger capacity** or **Mars mission architecture**).', additional_kwargs={'reasoning_content': \"Okay, the user is asking for fact number 2 about Starship. Let me check the conversation history to see what's been covered so far.\\n\\nIn the previous messages, the user started with fact 0, which was about Starship's structure and reusability. Then fact 1 was about the Raptor engines and their design. Now they want fact 2. \\n\\nThe assistant's last response outlined the next step as either the thermal protection system or cargo/passenger capabilities. The user's current query is for fact 2, so I need to pick one of those topics. The thermal protection system (TPS) is a critical aspect, especially since Starship is designed for reusability and missions to Mars, which involve extreme re-entry temperatures. \\n\\nI should structure the fact around the TPS materials and how they protect the spacecraft. The TPS includes the heat shield and other components. The heat shield uses a material called PICA-X, which is an improved version of NASA's PICA. It's designed to withstand temperatures up to 3,000°F (1,650°C) during re-entry. Additionally, the TPS includes a ceramic tile system for areas not covered by the heat shield, which helps in managing thermal stress and protecting the underlying structure.\\n\\nI need to make sure the information is accurate and up-to-date. Let me verify the materials used. Yes, PICA-X is the primary material for the heat shield. The tiles are made of a lightweight ceramic composite. Also, the TPS is crucial for both Earth and Mars re-entry, as Mars has a different atmospheric composition and density, requiring different thermal protection strategies.\\n\\nIncluding the purpose of the TPS in enabling reusability is important because it ties into Starship's goal of being a fully reusable spacecraft. This reduces costs for multiple missions. Also, mentioning the testing and development by SpaceX, such as the use of the heat shield in test flights, adds credibility.\\n\\nI should present this information clearly, following the structure from the previous facts. The summary should highlight the key points: materials used, temperature resistance, design features, and the role in reusability. The next steps would be to present this as fact 2 and ask if the user wants to proceed to fact 3, which could be about the cargo/passenger capabilities or another technical aspect.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 778, 'prompt_tokens': 923, 'total_tokens': 1701, 'completion_time': 1.649897169, 'completion_tokens_details': {'reasoning_tokens': 479}, 'prompt_time': 0.049873271, 'prompt_tokens_details': None, 'queue_time': 0.054136759, 'total_time': 1.69977044}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c14ae-2ae3-7422-ae88-14e1c2b4475c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 923, 'output_tokens': 778, 'total_tokens': 1701, 'output_token_details': {'reasoning': 479}})]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287a9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
